<html>
<head>
<title>Untitled Document</title>
<meta http-equiv="Content-Type" content="text/html; charset="utf-8"">
<link rel="stylesheet" href="../../css/text.css" type="text/css">
<style type="text/css">
<!--
.bodybg {
	background-attachment: fixed;
	background-repeat: no-repeat;
	background-position: right bottom;
}
-->
</style></head>

<body class="bodybg" bgcolor="#FFFFFF" background="../../../../../images/htmls/openwin/bg.jpg" text="#000000" leftmargin="0" topmargin="0" rightmargin="0" bottommargin="0" marginwidth="0" marginheight="0" >
<center><table width="95%" border="0" cellspacing="0" cellpadding="0">
  <tr>
      <td class=text> <p> 第一题<br>
          MPP <br>
          　　 大规模并行处理机。一般指规模非常大的并行计算机系统，含有成千上万个处理器。它一般采用分布的存储器，存储器一般为处理器私有，各处理器之间用消息传递的方式通信。大规模并行处理机的互连网络一般是专门设计定制的。<br>
          NUMA <br>
          　　 NUMA是非均匀存储访问模型的缩写。在NUMA中，共享存储器在物理上是分布的，所有的本地存储器构成了全局地址空间。NUMA与UMA的区别在于处理器访问本地存储器和群内共享存储器比访问远程存储器或全局共享存储器快。 
          <br>
          PRAM <br>
          　　 PRAM模型是随机存取并行机器模型，也称为共享存储的SIMD模型，是一种抽象的并行计算模型。在这种模型中，假定存在一个容量无限大的共享存储器，有有限个或无限个功能相同的处理器，且他们都具有简单的算术运算和逻辑判断功能，在任何时刻个处理器都可以通过共享存储单元相互交互数据。 
          <br>
          同步<br>
          　　 同步是在时间上强制使一组执行中的进程在某一点相互等待。在并行算法的各进程异步执行过程中，为了确保各处理器的正确工作顺序以及对共享资源的正确访问（资源的互斥访问），程序员需要在算法中恰当的位置设置同步点。同步可以用软件、硬件或固件的方法来实现。 
          <br>
          任务并行性<br>
          　　 任务并行性是将任务分解成一些子任务，只要所有必需的子任务已经完成，后续子任务就可以进行，很多的子任务都可以并行的执行。这种并行性表现为子任务的并行执行。 
          <br>
          <br>
          第二题<br>
          　　一个具有N个结点的Illiac网有<img src="../../images/st3_3.gif" width="18" height="10" align="absmiddle">条链路，直径为 
          <img src="../../images/st3_4.gif" width="39" height="16" align="absmiddle">，仅为纯网的直径的一半，对分宽度为<img src="../../images/st3_5.gif" width="29" height="16" align="absmiddle"> 
          。<br>
          <br>
          第三题<br>
          　　假设这三种结构中消息传递的方向都是双向的，需要考虑的实际上是，对于原来利用共享存储器可以在一个单位时间内完成的任意两个处理器之间的数据交换，现在在消息传递的机器上需要多少时间？ 
          <br>
          　　对于环，任意两个处理器间完成一次通信（传递一个数据）的时间复杂度为 <img src="../../images/st3_6.gif" width="45" height="13" align="absmiddle"> 
          也就是<img src="../../images/st3_7.gif" width="28" height="13" align="absmiddle">，所以在环上的运行时间上限为 
          <img src="../../images/st3_8.gif" width="33" height="13" align="absmiddle">；<br>
          　　对于二维网格，任意两个处理器间完成一次通信（传递一个数据）的时间复杂度为<img src="../../images/st3_10.gif" width="47" height="19" align="absmiddle"> 
          也就是<img src="../../images/st3_7.gif" width="28" height="13" align="absmiddle">，所以在二维网格上的运行时间上限为 
          <img src="../../images/st3_11.gif" width="44" height="19" align="absmiddle">； 
          <br>
          　　对于超立方体，任意两个处理器间完成一次通信（传递一个数据）的时间复杂度为 <img src="../../images/st3_12.gif" width="48" height="13" align="absmiddle">，所以在超立方体上的运行时间上限为 
          <img src="../../images/st3_13.gif" width="55" height="13" align="absmiddle">。 
          <br>
          <br>
          第四题<br>
          证明：<br>
          　　 依据途中描述的过程，算法的第一个步骤，每个处理器进行局部运算，对本地的n/p个数据进行累加，需要花费<img src="../../images/st3_14.gif" width="46" height="13" align="absmiddle"> 
          个时间步骤，然后问题变成了对p个处理器上的p个部分和进行累加，它可以在<img src="../../images/st3_15.gif" width="49" height="13" align="absmiddle"> 
          内完成，因此算法的并行运行时间为 <img src="../../images/st3_16.gif" width="89" height="13" align="absmiddle">，它的开销是 
          <img src="../../images/st3_17.gif" width="82" height="13" align="absmiddle">，只要 
          <img src="../../images/st3_18.gif" width="84" height="13" align="absmiddle">，则开销是 
          <img src="../../images/st3_19.gif" width="28" height="13" align="absmiddle">，这和串行运行时间是相同的，因此，并行系统是开销最优的。<br>
          <br>
          第五题<br>
          　　先把n×n的矩阵分成4个(n/2)×(n/2)的子矩阵，相应地，一个具有p个处理器的超立方体可以看作是4个p/4超立方体所构成。递归一直到每个子超立方体只含有一个处理器为止。来分析算法的运行时间，经过 
          <img src="../../images/st3_20.gif" width="36" height="14" align="absmiddle">次后递归结束，此时各个子块的大小为 
          <img src="../../images/st3_21.gif" width="104" height="19" align="absmiddle">，这些子块内部转置的时间量级为n<sup>2</sup>/p。每个待通信的子块大小为n<sup>2</sup>/p，使用存储转发选路所需的时间为 
          <img src="../../images/st3_22.gif" width="88" height="17" align="absmiddle">，递归 
          <img src="../../images/st3_23.gif" width="39" height="15" align="absmiddle"> 
          次的总通信时间为 <img src="../../images/st3_24.gif" width="271" height="17" align="absmiddle"> 
          。这样，算法总的运行时间为：<br>
          　　　 <img src="../../images/st3_5F25.gif" width="193" height="38" align="absmiddle"><br>
          第六题<br>
          　　设处理器个数为p，图G中共有n个结点，采用邻接矩阵的存储方式存储于矩阵A中。对矩阵A进行列方向的条带状划分，使得每个处理器上存储n/p列。最短路向量d也按照各个元素对应的结点分布到相应的处理器上。 
          <br>
          　　 对于每次迭代，各个处理器上所进行的计算主要是求最小值和更新向量d，这需要消耗 <img src="../../images/st3_26.gif" width="48" height="14" align="absmiddle"> 
          的时间。每次迭代中求最短边需要各个处理器之间的通信，并且新插入的最小树中的结点u也要通知给所有的处理器，这就需要一个全局求极值的通信过程和一个一到多广播的通信过程。 
          <br>
          　　 对于超立方体互联结构，求全局极值和一到多广播所需要的通信时间都是 <img src="../../images/st3_27.gif" width="80" height="15" align="absmiddle">　，这样n次迭代总的时间（包括计算时间和通信时间）为：<br>
          　　　 <img src="../../images/st3_28.gif" width="148" height="38" align="absmiddle"><br>
          <!--czp-wenda-daan-->
          <br>
          <br>
          　</p>
        </td>
  </tr>
</table>
  </center>

</body>
</html>
