<html>
<head>
<title>人工智能原理</title>
<meta http-equiv="Content-Type" content="text/html; charset="utf-8"">
<link rel="stylesheet" href="../../../../css/text.css" type="text/css">
</head>

<body bgcolor="#FFFFFF" text="#000000">
<table width="97%" border="0" cellspacing="0" cellpadding="0" align="right">
  <tr>
    <td> 
      <table width="100%" border="0" cellspacing="3" cellpadding="2">
        <tr> 
          <td> 
            <table width="40%" border="0" cellspacing="0" cellpadding="0" height="18" align="right">
              <tr> 
                <td class="pt10" background="../../../../images/pic/bg0401.gif"> 
                  <div align="center" class="chap">第六章　实例学习</div>
                </td>
              </tr>
            </table>
          </td>
        </tr>
      </table>
      <br>
      <span class="text"> 　　</span><span class="section">6.6 基于解释的学习</span><span class="text"><br>
      <br>
      　　基于解释的学习是近年出现的一种机器学习方法。这种方法利用单个的问题求解例子依领域知识构造出求解过程的因果解释结构，并获取控制知识，以便用于指导以后求解类似问题。<br>
      <br>
      　　</span><span class="part">6.6.1 基于解释学习简介</span><span class="text"><br>
      　　1.发展历史<br>
      　　基于解释学习（Explanation-Based Leaning,简称EBL）起源于经验学习的研究。50年代未，对神经元的模拟中发明了用一种符号来标记另一些符号的存储结构模型，这是早期的存储块（chunks）概念。在象棋大师的头脑中就保存着在各种情况下对弈经验的存储块。80年代初，Newell和Rosenbloom认为，通过获取任务环境中关于模型问题的知识，可以改进系统的性能，chunks可以作为对人类行为进行模拟的模型基础。通过观察问题求解过程，获取经验chunks，用其代替各个子目标中的复杂过程，可以明显提高系统求解的速度。由此奠定了经验学习的基础。<br>
      　　1983年，美国Illinois大学的Dejong提出了基于解释学习，在经验学习的基础上，运用领域知识对单个例子的问题求解作出解释，这是一种关于知识间因果关系的推理分析，可产生一般的控制策略。<br>
      　　1986年，Mitchell、Keller和Kedarcabelli提出了基于解释的概括化（Explanation-Based Generalization）的统一框架，把基于解释的学习过程定义为两个步骤：<br>
      　　（1） 通过求解一个例子来产生解释结构；<br>
      　　（2） 对该解释结构进行概括化，获取一般的控制规则。<br>
      　　此后，Dejong和Mooney提出了更一般的术语 -- 基于解释的学习。从此，基于解释的学习成为机器学习中的一个独立分枝。 <br>
      　　基于解释的学习从本质上说属于演绎学习，它是根据给定的领域知识，进行保真的演绎推理，存储有用结论，经过知识的求精和编辑，产生适于以后求解类似问题的控制知识。<br>
      　　基于解释学习获取的是控制知识，所以可以明显提高系统效率。解释的思想使人可以利用现有的演绎推理方法和计算机领域已有的成果。第十届国际人工智能会议的论文表明，知识获取的研究已从前几年的归纳学习为重点转到各种方法并驾齐驱，而基于解释学习的研究正逐步增多。<br>
      　　基于解释的学习可以用于软件再利用，计算机辅助设计和计算机示教等方面。<br>
      　　2.传统程序中的解释与EBL中的解释<br>
      　　解释在传统程序中的作用主要是说明程序、给出提示、向用户提供良好的可读性。按人工智能程序的特点，解释已被赋予新的含义，其作用是：<br>
      　　（1） 对所产生的结论的推理过程作详细说明，以增加系统的可接受性；<br>
      　　（2） 对错误决策进行追踪，发现知识库中知识的缺陷和错误的概念；<br>
      　　（3） 对初学的用户有进行训练。<br>
      　　解释的方法也因此由简单变得复杂了。一般采用的解释方法有：<br>
      　　（1） 预制文本法。预先用英文写好，并插入程序中；<br>
      　　（2） 执行追踪法。遍历目标树，通过总结与结论相关的目标，检索相关规则，以说明结论是如何得到的；<br>
      　　（3） 策略解释法。明确表示控制知识，即用元知识概括地描述，与领域规则完全分开。从策略的概括表示中产生解释，能为用户提供问题求解策略的解释。<br>
      　　基于解释的学习中主要采用了执行追踪法。通过遍历目标树，对知识相互之间的因果关系给出解释，而通过这种因果关系的分析，学习控制知识。<br>
      　　3.基于解释学习的工作原理<br>
      　　Mitchell等人提出了基于解释学习的两个步骤，具体过程如下：<br>
      　　（1）产生解释。用户输入实例后，系统首先进行问题求解。如由目标引导反向推理，从领域知识库中寻找有关规则，使其后件与目标匹配。找到这样的规则后，就把目标作为后件，该规则作为前件，并记录这一因果关系。然后以规则的前件作为子目标，进一步分解推理。如此反复，沿着因果链，直到求解结束。一旦得到解，便证明了该例的目标可满足，并获得了证明的因果解释结构。 
      <br>
      　　构造解释结构通常有两种方式：一是将问题求解的每一步推理所用的算子汇集，构成动作序列作为解释结构；另一种是自顶向下的遍历证明树结构。前者比较概括，略去了关于实例的某些事实描述；后者比较细致，每个事实都出现在证明树中。解释的构造可以在问题求解的同时进行，也可在问题求解结束后，沿着解路径进行。这两种方式形成了边解边学（Learning 
      while doing）和解完再学（Learning by solving）两种方法。<br>
      　　（2）对得到的解释结构以及事件进行概括。在这一步，通常采取的办法是将常量转换为变量，即把例子中的某些数据换成变量，并略去某些不重要的信息，只保留求解所必需的那些关键信息，经过某种方式的组合，形成产生式规则，从而获得概括性的控制知识。<br>
      </span></td>
  </tr>
</table>
</body>
</html>
